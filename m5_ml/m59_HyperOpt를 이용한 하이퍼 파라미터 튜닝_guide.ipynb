{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hyperopt in c:\\users\\h\\anaconda3\\lib\\site-packages (0.2.7)\n",
      "Requirement already satisfied: numpy in c:\\users\\h\\anaconda3\\lib\\site-packages (from hyperopt) (1.18.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\h\\anaconda3\\lib\\site-packages (from hyperopt) (1.5.0)\n",
      "Requirement already satisfied: six in c:\\users\\h\\anaconda3\\lib\\site-packages (from hyperopt) (1.15.0)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\h\\anaconda3\\lib\\site-packages (from hyperopt) (2.4)\n",
      "Requirement already satisfied: future in c:\\users\\h\\anaconda3\\lib\\site-packages (from hyperopt) (0.18.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\h\\anaconda3\\lib\\site-packages (from hyperopt) (4.47.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\h\\anaconda3\\lib\\site-packages (from hyperopt) (1.5.0)\n",
      "Requirement already satisfied: py4j in c:\\users\\h\\anaconda3\\lib\\site-packages (from hyperopt) (0.10.9.7)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\h\\anaconda3\\lib\\site-packages (from networkx>=2.2->hyperopt) (4.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Downloading pip-23.1.2-py3-none-any.whl (2.1 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 20.1.1\n",
      "    Uninstalling pip-20.1.1:\n",
      "      Successfully uninstalled pip-20.1.1\n",
      "Successfully installed pip-23.1.2\n"
     ]
    }
   ],
   "source": [
    "!python.exe -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperOpt 라이브러리의 주요 함수와 개념\n",
    "\n",
    "- fmin: 이 함수는 최적화 과정을 수행하는 주요 함수입니다. 이 함수는 목표 함수(fn), 검색 공간(space), 최적화 알고리즘(algo), 그리고 최대 평가 횟수(max_evals) 등을 인자로 받습니다. 이 함수는 최적의 하이퍼파라미터 설정을 찾기 위해 주어진 알고리즘을 사용하여 검색 공간을 탐색하고, 각 설정에 대해 목표 함수를 평가합니다.\n",
    "\n",
    "- tpe: 이것은 Tree-structured Parzen Estimator(TPE) 알고리즘을 나타내며, HyperOpt에서 사용할 수 있는 최적화 알고리즘 중 하나입니다. TPE는 베이지안 최적화 알고리즘의 한 종류로, 이전의 평가 결과를 기반으로 하여 다음에 테스트할 하이퍼파라미터를 선택합니다. 이렇게 하면 더 좋은 결과를 내는 하이퍼파라미터의 영역을 더 자주 탐색하게 됩니다.\n",
    "\n",
    "- hp: 이것은 HyperOpt의 검색 공간을 정의하는 데 사용되는 함수들을 담고 있는 모듈입니다. 예를 들어, hp.uniform('x', 0, 1)은 0과 1 사이에서 균일하게 분포한 실수 값을 가지는 'x'라는 하이퍼파라미터를 정의합니다. 다른 함수로는 hp.choice (여러 선택 사항 중 하나를 선택), hp.normal (정규 분포에서 값을 선택) 등이 있습니다.\n",
    "\n",
    "- STATUS_OK: 이것은 목표 함수가 성공적으로 완료되었음을 나타내는 상태 코드입니다. 목표 함수는 손실값과 상태 코드를 포함하는 딕셔너리를 반환해야 합니다. 이 상태 코드는 HyperOpt가 평가를 제대로 수행했는지 판단하는 데 사용됩니다. 만약 다른 값을 반환하면, HyperOpt는 해당 평가가 실패했다고 판단하고, 해당 설정을 더 이상 탐색하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree-structured Parzen Estimator (TPE)\n",
    "- 하이퍼파라미터 최적화를 위한 알고리즘 중 하나입니다. Bayesian optimization의 한 종류로, 하이퍼파라미터의 새로운 조합을 선택하는 방법으로 주로 사용됩니다.\n",
    "\n",
    "- TPE 알고리즘의 핵심 아이디어는 과거의 평가 결과를 기반으로 하이퍼파라미터의 좋은 값과 나쁜 값에 대한 확률 모델을 구축하고, 이 모델을 사용하여 다음에 시도할 하이퍼파라미터 값을 선택하는 것입니다.\n",
    "\n",
    "- TPE는 이를 위해 두 개의 확률 분포 l(x)와 g(x)를 사용합니다. 여기서 x는 하이퍼파라미터를 의미하며, l(x)는 과거의 좋은 하이퍼파라미터 값들에 대한 분포를 나타내고, g(x)는 모든 과거의 하이퍼파라미터 값들에 대한 분포를 나타냅니다.\n",
    "\n",
    "- 이 두 분포를 이용해 새로운 하이퍼파라미터 값 x를 선택할 때, l(x)/g(x)가 큰 값, 즉 과거의 좋은 하이퍼파라미터 값들에 더 가까운 값을 선택합니다.\n",
    "\n",
    "- 이런 방식으로, TPE는 점점 더 좋은 하이퍼파라미터 값을 찾아가는 탐색 과정을 수행합니다. 이는 전통적인 Grid Search나 Random Search에 비해 효율적이며, 보다 적은 평가로 좋은 하이퍼파라미터 값을 찾을 수 있게 합니다.\n",
    "\n",
    "- TPE 알고리즘 동작 로직\n",
    "\n",
    "    1. 초기화: 먼저 하이퍼파라미터 탐색 공간을 정의하고 초기 조합을 선택합니다. 일반적으로는 랜덤한 하이퍼파라미터 값을 선택하거나, 사전에 정의된 분포를 기반으로 샘플링합니다.\n",
    "\n",
    "    2. 평가 및 기록: 초기 조합으로 모델을 학습하고, 지정된 평가 지표(예: 정확도, 손실 함수 등)를 사용하여 성능을 측정합니다. 이 성능 값은 \"Trials\" 객체에 기록됩니다.\n",
    "\n",
    "    3. 모델 구성: \"Trials\" 객체에 기록된 이전 조합과 성능 값을 사용하여, TPE 알고리즘이 다음에 시도할 하이퍼파라미터 조합을 추정합니다. 이 추정은 베이지안 확률 모델을 사용하여 이루어집니다.\n",
    "\n",
    "    4. 조합 선택: 추정된 하이퍼파라미터 조합 중에서 다음 조합을 선택합니다. 일반적으로는 최대화하려는 평가 지표(성능 지표)에 기반하여 조합을 선택합니다.\n",
    "\n",
    "    5. 반복: 2단계부터 4단계까지의 과정을 반복합니다. 이전 탐색 결과와 현재 선택된 조합을 사용하여 새로운 추정을 수행하고, 최적의 하이퍼파라미터 조합을 찾기 위해 탐색을 진행합니다.\n",
    "    \n",
    "TPE는 확률 모델을 사용하기 때문에 적은 수의 시도로도 상대적으로 빠르게 최적의 조합을 찾을 수 있으며, 탐색 과정에서 불필요한 조합을 배제함으로써 탐색 효율성을 높일 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make_classification 함수 매개변수\n",
    "\n",
    "- n_samples: 생성할 샘플의 개수를 지정합니다. 기본값은 100입니다.\n",
    "- n_features: 독립 변수의 개수를 지정합니다. 기본값은 20입니다.\n",
    "- n_informative: 종속 변수와 관련된 독립 변수의 수를 지정합니다. 기본값은 2입니다.\n",
    "- n_redundant: 다른 독립 변수의 선형 조합으로 생성된 독립 변수의 수를 지정합니다. 기본값은 2입니다.\n",
    "- n_classes: 생성할 클래스(또는 레이블)의 개수를 지정합니다. 기본값은 2입니다.\n",
    "\n",
    "이 함수는 X와 y의 두 개의 배열을 반환합니다. X는 n_samples x n_features 크기의 2차원 배열로, 독립 변수를 포함하고 있습니다. y는 n_samples 크기의 1차원 배열로, 각 샘플의 클래스 레이블을 포함하고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1000개의 샘플, 10개의 독립 변수, 그리고 2개의 클래스로 구성된 가상 데이터셋을 생성\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 100/100 [00:02<00:00, 45.58trial/s, best loss: 0.050000000000000044]\n",
      "{'C': 0.06854594986236603}\n"
     ]
    }
   ],
   "source": [
    "# make_classification 함수는 sklearn.datasets 모듈의 일부로, 분류 문제에 사용할 수 있는 \n",
    "# 가상 데이터셋을 생성하는 데 사용\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 데이터 생성\n",
    "X, y = make_classification()\n",
    "\n",
    "# HyperOpt에 의해 최적화될 목표 함수를 정의합니다. \n",
    "# 이 함수는 손실값을 반환하며, 손실값이 최소가 되는 하이퍼파라미터를 찾는 것이 목표입니다.\n",
    "def objective(args):\n",
    "    # 모델 설정\n",
    "    # C는 규제의 역수로, C값이 작을수록 규제가 강하며 C값이 클수록 규제가 약해집니다.\n",
    "    # Logistic Regression 모델을 초기화하고, HyperOpt가 최적화할 하이퍼파라미터 C를 설정합니다.\n",
    "    model = LogisticRegression(C=args['C'])\n",
    "    \n",
    "    # 모델 검증\n",
    "    # 5-fold 교차 검증을 수행하고, 평균 정확도를 계산\n",
    "    score = cross_val_score(model, X, y, cv=5).mean()\n",
    "    \n",
    "    # 손실값 계산 (분류 문제에서는 정확도를 사용하므로 1 - 정확도를 반환)\n",
    "    # 분류 문제에서는 정확도를 사용하므로, 손실값을 1 - 정확도로 계산\n",
    "    loss = 1 - score\n",
    "    # 손실값과 상태 코드를 반환합니다.\n",
    "    return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "# 검색 공간 정의\n",
    "# 최적화할 하이퍼파라미터인 C의 범위를 정의합니다.\n",
    "space = {\n",
    "    'C': hp.loguniform('C', -5, 0)\n",
    "}\n",
    "\n",
    "# 최적화 실행\n",
    "# TPE 알고리즘을 사용하여 목표 함수를 최적화하고, \n",
    "# 최적의 하이퍼파라미터를 찾습니다. 최대 100회의 평가를 수행합니다.\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=100)\n",
    "\n",
    "print(best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.7\n"
     ]
    }
   ],
   "source": [
    "import hyperopt\n",
    "\n",
    "print(hyperopt.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperOpt 사용법\n",
    "- 입력 변수명과 입력값의 검색 공간 설정\n",
    "- 목적 함수의 설정\n",
    "- 목적 함수의 반환 최솟값을 가지는 최적 입력값을 유추"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "# -10 ~ 10까지 1간격을 가지는 입력 변수 x와 -15 ~ 15까지 1간격으로 입력 변수 y 설정.\n",
    "# hp.quniform(label, low, high, q) 함수는 low와 high 사이에서 일정 간격 q\n",
    "search_space = {'x': hp.quniform('x', -10, 10, 1), 'y': hp.quniform('y', -15, 15, 1) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import STATUS_OK\n",
    "\n",
    "# 목적 함수를 생성. 변숫값과 변수 검색 공간을 가지는 딕셔너리를 인자로 받고, 특정 값을 반환\n",
    "# search_space는 하이퍼파라미터의 조합을 나타내는 딕셔너리입니다. 이 딕셔너리는 'x'와 'y'라는 \n",
    "# 두 개의 키를 가지고 있습니다. 이 두 키는 각각 목표 함수에서 사용될 두 개의 변수를 나타냅니다.\n",
    "def objective_func(search_space):\n",
    "    x = search_space['x']\n",
    "    y = search_space['y']\n",
    "    retval = x**2 - 20*y  # retval이라는 변수에 목표 함수의 식을 계산한 결과를 저장\n",
    "    \n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 625.38trial/s, best loss: -224.0]\n",
      "best: {'x': -4.0, 'y': 12.0}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "import numpy as np\n",
    "\n",
    "# 입력 결괏값을 저장한 Trials 객체값 생성.\n",
    "trial_val = Trials()\n",
    "\n",
    "# 목적 함수의 최솟값을 반환하는 최적 입력 변숫값을 5번의 입력값 시도(max_evals=5)로 찾아냄.\n",
    "best_01 = fmin(fn=objective_func, space=search_space, algo=tpe.suggest, max_evals=5\n",
    "               , trials=trial_val, rstate=np.random.default_rng(seed=0))\n",
    "print('best:', best_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 454.80trial/s, best loss: -296.0]\n",
      "best: {'x': 2.0, 'y': 15.0}\n"
     ]
    }
   ],
   "source": [
    "trial_val = Trials()\n",
    "\n",
    "# max_evals를 20회로 늘려서 재테스트\n",
    "best_02 = fmin(fn=objective_func, space=search_space, algo=tpe.suggest, max_evals=20\n",
    "               , trials=trial_val, rstate=np.random.default_rng(seed=0))\n",
    "print('best:', best_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'loss': -64.0, 'status': 'ok'}, {'loss': -184.0, 'status': 'ok'}, {'loss': 56.0, 'status': 'ok'}, {'loss': -224.0, 'status': 'ok'}, {'loss': 61.0, 'status': 'ok'}, {'loss': -296.0, 'status': 'ok'}, {'loss': -40.0, 'status': 'ok'}, {'loss': 281.0, 'status': 'ok'}, {'loss': 64.0, 'status': 'ok'}, {'loss': 100.0, 'status': 'ok'}, {'loss': 60.0, 'status': 'ok'}, {'loss': -39.0, 'status': 'ok'}, {'loss': 1.0, 'status': 'ok'}, {'loss': -164.0, 'status': 'ok'}, {'loss': 21.0, 'status': 'ok'}, {'loss': -56.0, 'status': 'ok'}, {'loss': 284.0, 'status': 'ok'}, {'loss': 176.0, 'status': 'ok'}, {'loss': -171.0, 'status': 'ok'}, {'loss': 0.0, 'status': 'ok'}]\n"
     ]
    }
   ],
   "source": [
    "# fmin( )에 인자로 들어가는 Trials 객체의 result 속성에 파이썬 리스트로 목적 함수 반환값들이 저장됨\n",
    "# 리스트 내부의 개별 원소는 {'loss':함수 반환값, 'status':반환 상태값} 와 같은 딕셔너리임. \n",
    "print(trial_val.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': [-6.0, -4.0, 4.0, -4.0, 9.0, 2.0, 10.0, -9.0, -8.0, -0.0, -0.0, 1.0, 9.0, 6.0, 9.0, 2.0, -2.0, -4.0, 7.0, -0.0], 'y': [5.0, 10.0, -2.0, 12.0, 1.0, 15.0, 7.0, -10.0, 0.0, -5.0, -3.0, 2.0, 4.0, 10.0, 3.0, 3.0, -14.0, -8.0, 11.0, -0.0]}\n"
     ]
    }
   ],
   "source": [
    "# Trials 객체의 vals 속성에 {'입력변수명':개별 수행 시마다 입력된 값 리스트} 형태로 저장됨.\n",
    "print(trial_val.vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>losses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-9.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       x     y  losses\n",
       "0   -6.0   5.0   -64.0\n",
       "1   -4.0  10.0  -184.0\n",
       "2    4.0  -2.0    56.0\n",
       "3   -4.0  12.0  -224.0\n",
       "4    9.0   1.0    61.0\n",
       "5    2.0  15.0  -296.0\n",
       "6   10.0   7.0   -40.0\n",
       "7   -9.0 -10.0   281.0\n",
       "8   -8.0   0.0    64.0\n",
       "9   -0.0  -5.0   100.0\n",
       "10  -0.0  -3.0    60.0\n",
       "11   1.0   2.0   -39.0\n",
       "12   9.0   4.0     1.0\n",
       "13   6.0  10.0  -164.0\n",
       "14   9.0   3.0    21.0\n",
       "15   2.0   3.0   -56.0\n",
       "16  -2.0 -14.0   284.0\n",
       "17  -4.0  -8.0   176.0\n",
       "18   7.0  11.0  -171.0\n",
       "19  -0.0  -0.0     0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# results에서 loss 키값에 해당하는 밸류들을 추출하여 list로 생성. \n",
    "losses = [loss_dict['loss'] for loss_dict in trial_val.results]\n",
    "\n",
    "# DataFrame으로 생성.\n",
    "result_df = pd.DataFrame({'x': trial_val.vals['x'], 'y': trial_val.vals['y'], 'losses': losses})\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperOpt를 이용한 XGBoost 하이퍼 파라미터 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과제2_0523.\n",
    "위스콘신 유방암 데이터 세트를 로딩해서 XGBooster 알고리즘으로 모델링 및 평가를 수행하세요. 단 HyperOpt를 이용해서 하이퍼 파라미터를 최적화하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  앙상블 학습\n",
    "\n",
    "* 앙상블 학습의 유형은 보팅, 배깅, 부스팅 세가지로 나눌 수 있으며 이외에도 스태깅을 포함한 다양한 앙상블 방법이 있다.\n",
    "* 보팅의 경우 서로 다른 알고리즘을 가진 분류기를 결합하는 것이고 배깅의 경우 각각의 분류기가 모두 같은 유형의 알고리즘 기반이다.\n",
    "* 정형 데이터의 예측 분석 영역에서는 매우 높은 예측 성능. Bagging 과 Boosting\n",
    "* 배깅 방식의 대표인 Random Forest는 뛰어난 예측 성능, 상대적으로 빠른 수행시간, 유연성 등으로 애용.\n",
    "* 부스팅의 효시는 Gradient Boosting, 한 단계 발전시키면서도 시간 단축시킨 XgBoost, LightGBM이 정형 데이터의 분류 영역에서 \n",
    "  활용도 확대\n",
    "* 앙상블의 앙상블이라고 불리는 스태킹 기법\n",
    "* 앙상블의 기본 알고리즘은 결정 트리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier\n",
    "- 하드 보팅 : 다수결 원칙, 다수의 분류기가 결정한 예측값을 최종 보팅 결과값으로 선정\n",
    "- 소프트 보팅 : 분류기들의 레이블 값 결정 확률을 모두 더해서 평균하고 이들 중 가장 높은 레이블 값을 최종 보팅 결과값으로 선정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting 분류기 정확도: 0.9474\n",
      "LogisticRegression 정확도: 0.9386\n",
      "KNeighborsClassifier 정확도: 0.9386\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 개별 모델은 로지스틱 회귀와 KNN 임. \n",
    "lr_clf = LogisticRegression()\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=8)\n",
    "\n",
    "# 개별 모델을 소프트 보팅 기반의 앙상블 모델로 구현한 분류기 \n",
    "vo_clf = VotingClassifier( estimators=[('LR',lr_clf),('KNN',knn_clf)] , voting='soft' )\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, \n",
    "                                                    test_size=0.2 , random_state= 156)\n",
    "\n",
    "# VotingClassifier 학습/예측/평가. \n",
    "vo_clf.fit(X_train , y_train)\n",
    "pred = vo_clf.predict(X_test)\n",
    "print('Voting 분류기 정확도: {0:.4f}'.format(accuracy_score(y_test , pred)))\n",
    "\n",
    "# 개별 모델의 학습/예측/평가.\n",
    "classifiers = [lr_clf, knn_clf]\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(X_train , y_train)\n",
    "    pred = classifier.predict(X_test)\n",
    "    class_name= classifier.__class__.__name__\n",
    "    print('{0} 정확도: {1:.4f}'.format(class_name, accuracy_score(y_test , pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "https://eunsukimme.github.io/ml/2019/11/26/Random-Forest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 랜덤 포레스트(Random Forest)\n",
    "- 앙상블 기법 중 하나로, 의사결정나무(Decision Tree)를 기반으로 한 분류 및 회귀 알고리즘입니다. 랜덤 포레스트는 여러 개의 의사결정나무를 조합하여 강력한 예측 모델을 구축하고, 과적합을 방지하며 일반화 성능을 향상시킵니다.\n",
    "\n",
    "- 랜덤 포레스트의 동작 원리\n",
    "\n",
    "    - 데이터 샘플링: 원본 데이터에서 무작위로 중복을 허용하여 샘플을 선택합니다. 이렇게 선택된 샘플들을 사용하여 각각의 의사결정나무를 학습시킵니다. 이러한 방식을 부트스트래핑(bootstrapping)이라고 합니다.\n",
    "\n",
    "    - 특징 선택: 각 의사결정나무의 학습 과정에서 특징 선택 시 무작위로 일부 특징만을 고려합니다. 이는 의사결정나무 간의 다양성을 증가시켜 모델의 예측력을 향상시키는 역할을 합니다.\n",
    "\n",
    "    - 의사결정나무 학습: 선택된 샘플과 특징을 사용하여 의사결정나무를 학습시킵니다. 각 의사결정나무는 주어진 데이터에 대해 분할 기준과 분기를 결정하여 예측 규칙을 생성합니다.\n",
    "\n",
    "    - 예측 결합: 학습된 모든 의사결정나무를 사용하여 새로운 데이터의 예측값을 도출합니다. 분류 문제에서는 다수결 투표를 통해 가장 많은 표를 받은 클래스가 최종 예측값이 됩니다. 회귀 문제에서는 평균값을 사용합니다.\n",
    "\n",
    "- 랜덤 포레스트 장점\n",
    "\n",
    "    - 과적합 방지: 랜덤 포레스트는 의사결정나무의 과적합 문제를 완화시킵니다. 샘플링과 특징 선택의 무작위성을 통해 다양한 의사결정나무를 조합하고, 이들의 예측을 평균화함으로써 일반화 성능을 향상시킵니다.\n",
    "\n",
    "    - 변수 중요도 제공: 랜덤 포레스트는 변수의 중요도를 계산할 수 있습니다. 각 의사결정나무에서 변수의 사용 빈도나 분산 기준에 따라 중요도를 측정하고, 이를 모든 의사결정나무에서 평균화하여 변수의 상대적 중요도를 얻을 수 있습니다. 이를 통해 데이터에서 어떤 변수가 예측에 가장 큰 영향을 미치는지를 알 수 있습니다.\n",
    "\n",
    "    - 안정성과 신뢰성: 랜덤 포레스트는 여러 개의 의사결정나무를 결합한 모델이므로, 개별 의사결정나무의 오류나 노이즈에 덜 민감합니다. 이를 통해 안정적이고 신뢰성 있는 예측을 제공할 수 있습니다.\n",
    "\n",
    "    - 다양한 데이터 타입 처리: 랜덤 포레스트는 범주형 데이터와 연속형 데이터 모두를 처리할 수 있습니다. 범주형 변수의 경우 원-핫 인코딩 등의 전처리 과정이 필요하지 않습니다.\n",
    "\n",
    "    - 비교적 빠른 학습과 예측 속도: 의사결정나무의 학습과 예측이 병렬로 수행되므로, 데이터가 크거나 차원이 높아도 상대적으로 빠른 학습 및 예측 속도를 보장할 수 있습니다.\n",
    "\n",
    "- 랜덤 포레스트는 의사결정나무의 단점인 해석력이 다소 떨어진다는 점을 가지고 있습니다. 여러 개의 의사결정나무를 조합하므로 최종 모델의 해석이 어려울 수 있습니다. 또한, 랜덤 포레스트는 모델 구성을 위해 많은 수의 의사결정나무를 사용해야 하므로, 모델의 복잡성과 메모리 사용량이 증가할 수 있습니다.\n",
    "\n",
    "- 랜덤 포레스트는 다양한 분류 및 회귀 문제에 적용할 수 있는 강력한 알고리즘으로 알려져 있으며, 데이터셋의 특성과 목표에 맞게 사용될 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과제1_0518. 타이타닉 데이터 셋에 대하여 필요한 전처리를 수행한 후 랜덤포레스트 알고리즘을 적용하여 평가 및\n",
    "성능 개선을 수행하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일괄 전처리 사용자 함수(null 처리, 불필요 칼럼 삭제, 레이블 인코딩) \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Null 처리 함수\n",
    "# Age(평균), Cabin('N'), Embarked('N'), Fare(0)\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(),inplace=True)\n",
    "    df['Cabin'].fillna('N',inplace=True)\n",
    "    df['Embarked'].fillna('N',inplace=True)\n",
    "    df['Fare'].fillna(0,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
    "# PassengerId, Name, Ticket(티켓번호)\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 수행.\n",
    "# Cabin(선실번호 첫문자만 추출 후 인코딩), Sex(성별), Embarked(중간 정착 항구)\n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin','Sex','Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 앞에서 설정한 Data Preprocessing 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8491620111731844"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원본 데이터를 재로딩, 데이터 가공, 학습데이터/테스트 데이터 분할 후 학습 및 예측\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "titanic_df = pd.read_csv('./dataset/train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df= titanic_df.drop('Survived', axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, \\\n",
    "                                                    test_size=0.20, random_state=11)\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "\n",
    "rf_clf.fit(X_train , y_train)\n",
    "pred = rf_clf.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test,pred)\n",
    "accuracy_rf\n",
    "# len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 8, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "최고 예측 정확도: 0.8259\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[50, 100, 200, 300],\n",
    "    'max_depth' : [2, 4, 6, 8], \n",
    "    'min_samples_leaf' : [2, 6, 8, 10, 12, 18 ],\n",
    "    'min_samples_split' : [2, 4, 8, 12, 16]\n",
    "}\n",
    "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
    "rf_clf = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "grid_cv = GridSearchCV(rf_clf , param_grid=params , cv=5, n_jobs=-1 )\n",
    "grid_cv.fit(X_train , y_train)\n",
    "\n",
    "print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.8659\n"
     ]
    }
   ],
   "source": [
    "rf_clf1 = RandomForestClassifier(n_estimators=200, max_depth=8, min_samples_leaf=2, \\\n",
    "                                 min_samples_split=2, random_state=0)\n",
    "rf_clf1.fit(X_train , y_train)\n",
    "pred = rf_clf1.predict(X_test)\n",
    "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test , pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과제2_0513. 과제1로 부터 변수 중요도를 도출하고 시각화하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "ftr_importances_values = rf_clf1.feature_importances_\n",
    "ftr_importances = pd.Series(ftr_importances_values,index=X_train.columns  )\n",
    "ftr_top5 = ftr_importances.sort_values(ascending=False)[:5]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Feature importances Top 5')\n",
    "sns.barplot(x=ftr_top5 , y = ftr_top5.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBM(Gradient Boosting Machine)\n",
    "- 부스팅 알고리즘은 여러 개의 약한 학습기(weak learner)를 순차적으로 학습-예측하면서 잘못 예측한 데이터에 가중치 부여를 통해 오류를 개선해 나가면서 학습하는 방식\n",
    "- 가중치 업데이트를 경사 하강법(Gradient Descent)를 이용한다.\n",
    "- 분류는 물론이고 회귀도 가능\n",
    "- 파라미터 : n_estimators, max_depth, max_features\n",
    " - loss : 경사하강법에서 사용할 비용함수 지정. 기본값 deviance 적용\n",
    " - learning_rate : GBM이 학습할 때마다 적용할 학습률.오류값 보정 시 적용하는 계수로 0 ~ 1 사이의 값 지정. 기본값은 0.1. 작게 설정하면 예측성능이 높아지나 수행시간이 오래 걸리고 큰 값을 적용하면 예측 성능이 떨어질 가능성이 높으나 빠른 수행이 가능. n_estimator와 상호 보완적으로 조합해 사용\n",
    " - n_estimator : weak learner의 개수\n",
    " - subsample : weak learner가 학습에 사용하는 데이터의 샘플링 비율. 기본값은 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "titanic_df = pd.read_csv('./dataset/train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df= titanic_df.drop('Survived', axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, \\\n",
    "                                                    test_size=0.20, random_state=11)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=0)\n",
    "gb_clf.fit(X_train , y_train)\n",
    "gb_pred = gb_clf.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "\n",
    "print('GBM 정확도: {0:.4f}'.format(gb_accuracy))\n",
    "print(\"GBM 수행 시간: {0:.1f} 초 \".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[50, 100, 200, 300],\n",
    "    'learning_rate' : [ 0.05, 0.1, 0.15, 0.2]\n",
    "}\n",
    "grid_cv = GridSearchCV(gb_clf , param_grid=params , cv=5 ,verbose=1)\n",
    "grid_cv.fit(X_train , y_train)\n",
    "print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV를 이용하여 최적으로 학습된 estimator로 predict 수행. \n",
    "gb_pred = grid_cv.best_estimator_.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "print('GBM 정확도: {0:.4f}'.format(gb_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

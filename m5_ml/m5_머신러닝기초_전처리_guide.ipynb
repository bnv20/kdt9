{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 레이블 인코딩(Label encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 변환값: [0 1 4 5 3 3 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "items=['TV','냉장고','전자렌지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
    "\n",
    "# LabelEncoder를 객체로 생성한 후 , fit( ) 과 transform( ) 으로 label 인코딩 수행. \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "print('인코딩 변환값:',labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 클래스: ['TV' '냉장고' '믹서' '선풍기' '전자렌지' '컴퓨터']\n"
     ]
    }
   ],
   "source": [
    "print('인코딩 클래스:',encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "디코딩 원본 값: ['TV' '냉장고' '전자렌지' '컴퓨터' '선풍기' '선풍기' '믹서' '믹서']\n"
     ]
    }
   ],
   "source": [
    "print('디코딩 원본 값:',encoder.inverse_transform([0, 1, 4, 5, 3, 3, 2, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원-핫 인코딩(One-Hot encoding)\n",
    "- 원-핫 인코딩은 범주형 데이터를 처리할 때 많이 사용하는 기법으로, 각 범주를 벡터의 요소로 변환하여 해당 범주에 해당하면 1, 그렇지 않으면 0을 할당하는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 4 5 3 3 2 2]\n",
      "[[0]\n",
      " [1]\n",
      " [4]\n",
      " [5]\n",
      " [3]\n",
      " [3]\n",
      " [2]\n",
      " [2]]\n",
      "원-핫 인코딩 데이터\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n",
      "원-핫 인코딩 데이터 차원\n",
      "(8, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "items=['TV','냉장고','전자렌지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "print(labels)\n",
    "# 2차원 데이터로 변환합니다. \n",
    "# 변환된 labels는 1차원 배열이지만, OneHotEncoder는 2차원 데이터를 입력으로 받으므로 reshape(-1, 1)을 \n",
    "# 사용하여 labels를 2차원으로 변환합니다. -1은 나머지 차원을 자동으로 계산하라는 의미입니다.\n",
    "labels = labels.reshape(-1,1)\n",
    "print(labels)\n",
    "# 원-핫 인코딩을 적용합니다.\n",
    "oh_encoder = OneHotEncoder()\n",
    "oh_labels = oh_encoder.fit_transform(labels)\n",
    "# toarray() 함수는 sparse matrix를 dense format(일반적인 2차원 배열 형태)으로 변환하는데 사용\n",
    "print('원-핫 인코딩 데이터')\n",
    "print(oh_labels.toarray())\n",
    "print('원-핫 인코딩 데이터 차원')\n",
    "print(oh_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_TV</th>\n",
       "      <th>item_냉장고</th>\n",
       "      <th>item_믹서</th>\n",
       "      <th>item_선풍기</th>\n",
       "      <th>item_전자렌지</th>\n",
       "      <th>item_컴퓨터</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_TV  item_냉장고  item_믹서  item_선풍기  item_전자렌지  item_컴퓨터\n",
       "0        1         0        0         0          0         0\n",
       "1        0         1        0         0          0         0\n",
       "2        0         0        0         0          1         0\n",
       "3        0         0        0         0          0         1\n",
       "4        0         0        0         1          0         0\n",
       "5        0         0        0         1          0         0\n",
       "6        0         0        1         0          0         0\n",
       "7        0         0        1         0          0         0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q.Pandas를 이용해서 간편하게 원핫인코딩을 수행하세요. \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'item':['TV','냉장고','전자렌지','컴퓨터','선풍기','선풍기','믹서','믹서'] })\n",
    "df = pd.get_dummies(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과제2_0516. 아래 animals 데이터에 대하여 one-hot encoding을 수행한 후 데이터 프레임으로 출력하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# 동물 분류 문제에 사용할 데이터\n",
    "animals = ['고양이', '개', '새', '개', '새', '새', '고양이', '고양이']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 피처 스케일링과 정규화\n",
    "\n",
    "StandardScaler와 MinMaxScaler는 모두 scikit-learn 라이브러리의 데이터 전처리 도구입니다. 이들은 특성 스케일링(feature scaling)을 수행하는 데 사용되며, 이는 모든 특성이 동일한 스케일을 갖도록 변환하는 과정입니다. 특성의 스케일이 다르면 머신러닝 알고리즘의 성능에 부정적인 영향을 미칠 수 있습니다.\n",
    "\n",
    "- StandardScaler: 이 스케일러는 특성을 표준화합니다. 특성의 평균을 0, 표준 편차를 1로 변경하여 정규 분포를 따르도록 만듭니다. 이는 각 특성의 값에서 특성의 평균을 빼고 표준 편차로 나눔으로써 수행됩니다. 표준화는 특성의 분포가 정규 분포가 아닐 때, 또는 특성 간의 스케일 차이를 제거하려 할 때 유용합니다.\n",
    "\n",
    "- MinMaxScaler: 이 스케일러는 특성을 정규화합니다. 특성의 최소값을 0, 최대값을 1로 변경하여 모든 특성이 0과 1 사이의 값으로 변환되도록 합니다. 이는 각 특성의 값에서 특성의 최소값을 빼고, 그 결과를 특성의 범위(최대값 - 최소값)로 나눔으로써 수행됩니다. 정규화는 특성의 분포가 균등하게 퍼져 있을 때, 또는 특성의 최소값과 최대값이 명확히 정해져 있을 때 유용합니다.\n",
    "\n",
    "이 두 가지 스케일러는 모두 데이터의 분포나 값의 범위를 변경하지만, 어떤 스케일러를 사용할지는 문제의 요구 사항과 데이터의 특성에 따라 달라집니다. 또한, 이들 스케일러를 사용할 때는 항상 훈련 데이터를 기반으로 스케일러를 학습시킨 후, 이를 훈련 데이터와 테스트 데이터에 모두 적용해야 합니다. 이렇게 해야 테스트 데이터가 훈련 데이터와 동일한 방식으로 변환되므로, 모델이 일관된 입력을 받을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 들의 평균 값\n",
      "sepal length (cm)    5.843333\n",
      "sepal width (cm)     3.057333\n",
      "petal length (cm)    3.758000\n",
      "petal width (cm)     1.199333\n",
      "dtype: float64\n",
      "\n",
      "feature 들의 분산 값\n",
      "sepal length (cm)    0.685694\n",
      "sepal width (cm)     0.189979\n",
      "petal length (cm)    3.116278\n",
      "petal width (cm)     0.581006\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "# 붓꽃 데이터 셋을 로딩하고 DataFrame으로 변환합니다. \n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "\n",
    "print('feature 들의 평균 값')\n",
    "print(iris_df.mean())\n",
    "print('\\nfeature 들의 분산 값')\n",
    "print(iris_df.var())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 들의 평균 값\n",
      "sepal length (cm)   -1.690315e-15\n",
      "sepal width (cm)    -1.842970e-15\n",
      "petal length (cm)   -1.698641e-15\n",
      "petal width (cm)    -1.409243e-15\n",
      "dtype: float64\n",
      "\n",
      "feature 들의 분산 값\n",
      "sepal length (cm)    1.006711\n",
      "sepal width (cm)     1.006711\n",
      "petal length (cm)    1.006711\n",
      "petal width (cm)     1.006711\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# StandardScaler객체 생성\n",
    "scaler = StandardScaler()\n",
    "# StandardScaler 로 데이터 셋 변환. fit( ) 과 transform( ) 호출.  \n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "#transform( )시 scale 변환된 데이터 셋이 numpy ndarry로 반환되어 이를 DataFrame으로 변환\n",
    "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
    "print('feature 들의 평균 값')\n",
    "print(iris_df_scaled.mean())\n",
    "print('\\nfeature 들의 분산 값')\n",
    "print(iris_df_scaled.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm)    0.0\n",
      "sepal width (cm)     0.0\n",
      "petal length (cm)    0.0\n",
      "petal width (cm)     0.0\n",
      "dtype: float64\n",
      "sepal length (cm)    1.0\n",
      "sepal width (cm)     1.0\n",
      "petal length (cm)    1.0\n",
      "petal width (cm)     1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Q. MinMaxScaler를 사용하여 정규화하세요.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(iris_df)\n",
    "iris_mscaled = scaler.transform(iris_df)\n",
    "\n",
    "iris_df_mscaled = pd.DataFrame(data=iris_mscaled, columns = iris.feature_names)\n",
    "iris_df_mscaled\n",
    "\n",
    "print(iris_df_mscaled.min())\n",
    "print(iris_df_mscaled.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스케일러를 사용할 때는 항상 훈련 데이터를 기반으로 스케일러를 학습시킨 후, 이를 훈련 데이터와 테스트 데이터에 모두 적용\n",
    "- fit 메서드는 훈련 데이터에 대한 스케일링 파라미터(평균과 표준편차)를 계산하고, transform 메서드는 이 파라미터를 사용해 데이터를 실제로 변환합니다. fit 메서드는 훈련 데이터에만 적용되어야 하며, 이렇게 학습된 스케일러는 훈련 데이터와 테스트 데이터에 모두 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 가상의 데이터 생성\n",
    "X, y = np.arange(20).reshape((10, 2)), range(10)\n",
    "\n",
    "# 데이터를 훈련 데이터와 테스트 데이터로 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# StandardScaler 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 훈련 데이터를 사용해 스케일러 학습\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# 스케일러를 사용해 훈련 데이터와 테스트 데이터 변환\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

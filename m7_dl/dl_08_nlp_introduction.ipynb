{"cells":[{"cell_type":"markdown","metadata":{"id":"8Ce2SFsxPHWA"},"source":["# 텍스트를 위한 딥러닝"]},{"cell_type":"markdown","metadata":{"id":"fN2ZLGlaPHWA"},"source":["## 자연어 처리 소개"]},{"cell_type":"markdown","metadata":{"id":"6b--VkdzPHWB"},"source":["## 텍스트 데이터 준비"]},{"cell_type":"markdown","metadata":{"id":"VEToG7w2PHWB"},"source":["### 텍스트 표준화"]},{"cell_type":"markdown","metadata":{"id":"oWyNOPSKPHWB"},"source":["### 텍스트 분할 (토큰화)"]},{"cell_type":"markdown","metadata":{"id":"5h-ecuq5PHWB"},"source":["### 어휘 인덱싱"]},{"cell_type":"markdown","metadata":{"id":"vThLgagxPHWC"},"source":["### `TextVectorization` 층 사용하기"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"e6AsY6CHPHWC","executionInfo":{"status":"ok","timestamp":1689214386233,"user_tz":-540,"elapsed":426,"user":{"displayName":"kevin park","userId":"02703084888761299921"}}},"outputs":[],"source":["import string\n","\n","class Vectorizer:\n","    def standardize(self, text):\n","        text = text.lower()\n","        return \"\".join(char for char in text if char not in string.punctuation)\n","\n","    def tokenize(self, text):\n","        return text.split()\n","\n","    def make_vocabulary(self, dataset):\n","        self.vocabulary = {\"\": 0, \"[UNK]\": 1} # 특수한 토큰인 \"\" (비어있는 문자열)과 \"[UNK]\" (알려지지 않은 토큰)을 초기값으로 설정\n","        for text in dataset:\n","            text = self.standardize(text)\n","            tokens = self.tokenize(text)\n","            for token in tokens:\n","                if token not in self.vocabulary:\n","                    self.vocabulary[token] = len(self.vocabulary) # 단어 집합에 이미 들어있는 토큰의 개수로, 각 토큰에 고유한 정수를 할당\n","        self.inverse_vocabulary = dict(\n","            (v, k) for k, v in self.vocabulary.items()) # self.vocabulary는 단어를 키로 하고 해당 단어에 대응하는 고유한 정수를 값\n","                                                        # self.inverse_vocabulary 정수를 키로 하고 단어를 값으로 가지는 딕셔너리\n","    def encode(self, text):\n","        text = self.standardize(text)\n","        tokens = self.tokenize(text)\n","        return [self.vocabulary.get(token, 1) for token in tokens] #  토큰이 단어 집합에 없다면 1을 반환\n","\n","    def decode(self, int_sequence):\n","        return \" \".join(\n","            self.inverse_vocabulary.get(i, \"[UNK]\") for i in int_sequence) # 정수가 단어 집합에 없다면 \"[UNK]\" 를 반환\n","\n","vectorizer = Vectorizer()\n","dataset = [\n","    \"I write, erase, rewrite\",\n","    \"Erase again, and then\",\n","    \"A poppy blooms.\",\n","]\n","vectorizer.make_vocabulary(dataset)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"qinD6gJ1PHWE","outputId":"e686beae-9e04-4399-afaf-c0d4e858d146","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689214417845,"user_tz":-540,"elapsed":447,"user":{"displayName":"kevin park","userId":"02703084888761299921"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[2, 3, 5, 7, 1, 5, 6]\n"]}],"source":["test_sentence = \"I write, rewrite, and still rewrite again\"\n","encoded_sentence = vectorizer.encode(test_sentence)\n","print(encoded_sentence)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"lTIHl1YNPHWF","outputId":"6ecab61b-57e0-493c-a9fa-17cc4fea6037","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689214429849,"user_tz":-540,"elapsed":394,"user":{"displayName":"kevin park","userId":"02703084888761299921"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["i write rewrite and [UNK] rewrite again\n"]}],"source":["decoded_sentence = vectorizer.decode(encoded_sentence)\n","print(decoded_sentence)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"COXYu3qdPHWF","executionInfo":{"status":"ok","timestamp":1689214716208,"user_tz":-540,"elapsed":7363,"user":{"displayName":"kevin park","userId":"02703084888761299921"}}},"outputs":[],"source":["from tensorflow.keras.layers import TextVectorization\n","text_vectorization = TextVectorization(\n","    output_mode=\"int\",\n",")"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"5OWCEbFEPHWF","executionInfo":{"status":"ok","timestamp":1689214809152,"user_tz":-540,"elapsed":504,"user":{"displayName":"kevin park","userId":"02703084888761299921"}}},"outputs":[],"source":["import re\n","import string\n","import tensorflow as tf\n","\n","def custom_standardization_fn(string_tensor):\n","    lowercase_string = tf.strings.lower(string_tensor)\n","    return tf.strings.regex_replace(\n","        lowercase_string, f\"[{re.escape(string.punctuation)}]\", \"\")\n","\n","def custom_split_fn(string_tensor):\n","    return tf.strings.split(string_tensor)\n","\n","text_vectorization = TextVectorization(\n","    output_mode=\"int\",\n","    standardize=custom_standardization_fn,\n","    split=custom_split_fn,\n",")"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"a8KKZ2aGPHWG","executionInfo":{"status":"ok","timestamp":1689214834345,"user_tz":-540,"elapsed":480,"user":{"displayName":"kevin park","userId":"02703084888761299921"}}},"outputs":[],"source":["dataset = [\n","    \"I write, erase, rewrite\",\n","    \"Erase again, and then\",\n","    \"A poppy blooms.\",\n","]\n","text_vectorization.adapt(dataset)"]},{"cell_type":"markdown","metadata":{"id":"ivDt8LVRPHWG"},"source":["**어휘 사전 출력하기**"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"6piMhRMEPHWG","outputId":"08f16da8-c0c1-4098-b74a-2c34d2dee3a6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689214887143,"user_tz":-540,"elapsed":407,"user":{"displayName":"kevin park","userId":"02703084888761299921"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['',\n"," '[UNK]',\n"," 'erase',\n"," 'write',\n"," 'then',\n"," 'rewrite',\n"," 'poppy',\n"," 'i',\n"," 'blooms',\n"," 'and',\n"," 'again',\n"," 'a']"]},"metadata":{},"execution_count":8}],"source":["text_vectorization.get_vocabulary()"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"ZQj8w725PHWG","outputId":"b813dc60-e2b4-4c97-aab5-cd0d9934f02c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689214992299,"user_tz":-540,"elapsed":362,"user":{"displayName":"kevin park","userId":"02703084888761299921"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor([ 7  3  5  9  1  5 10], shape=(7,), dtype=int64)\n"]}],"source":["vocabulary = text_vectorization.get_vocabulary()\n","test_sentence = \"I write, rewrite, and still rewrite again\"\n","encoded_sentence = text_vectorization(test_sentence)\n","print(encoded_sentence)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"2ACo5XXcPHWG","outputId":"b5d6fa8f-eb13-4d4f-c5ae-5cbb95e9fc24","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689215002996,"user_tz":-540,"elapsed":718,"user":{"displayName":"kevin park","userId":"02703084888761299921"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["i write rewrite and [UNK] rewrite again\n"]}],"source":["# still은 out of vacabulary\n","inverse_vocab = dict(enumerate(vocabulary))\n","decoded_sentence = \" \".join(inverse_vocab[int(i)] for i in encoded_sentence)\n","print(decoded_sentence)"]},{"cell_type":"markdown","metadata":{"id":"VjnG_PtiPHWH"},"source":["## 단어 그룹을 표현하는 두 가지 방법: 집합과 시퀀스"]},{"cell_type":"markdown","metadata":{"id":"KFQeM-FUPHWH"},"source":["### IMDB 영화 리뷰 데이터 준비하기"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"JHC5wgjxPHWH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689215402611,"user_tz":-540,"elapsed":12303,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"0471a92d-650d-442e-e56c-e7e38ff50a7a"},"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 80.2M  100 80.2M    0     0  20.8M      0  0:00:03  0:00:03 --:--:-- 20.8M\n"]}],"source":["!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","!tar -xf aclImdb_v1.tar.gz"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"irDrd9GJPHWH","executionInfo":{"status":"ok","timestamp":1689215486000,"user_tz":-540,"elapsed":1881,"user":{"displayName":"kevin park","userId":"02703084888761299921"}}},"outputs":[],"source":["!rm -r aclImdb/train/unsup"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"pPt42d2WPHWH","outputId":"d4aa251b-777b-4b70-e18c-a3c1aa628b96","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689215537061,"user_tz":-540,"elapsed":1209,"user":{"displayName":"kevin park","userId":"02703084888761299921"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"]}],"source":["!cat aclImdb/train/pos/4077_10.txt"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"VqMxuzj8PHWI","executionInfo":{"status":"ok","timestamp":1689215788530,"user_tz":-540,"elapsed":312,"user":{"displayName":"kevin park","userId":"02703084888761299921"}}},"outputs":[],"source":["# 훈련 세트에서 일부 데이터를 추출하여 새로운 검증 세트를 생성\n","import os, pathlib, shutil, random\n","\n","base_dir = pathlib.Path(\"aclImdb\") # \"aclImdb\"라는 이름의 디렉토리에 대한 경로 객체를 생성\n","val_dir = base_dir / \"val\"\n","train_dir = base_dir / \"train\"\n","for category in (\"neg\", \"pos\"):\n","    os.makedirs(val_dir / category)\n","    files = os.listdir(train_dir / category) # 특정 디렉토리 내의 모든 파일과 디렉토리의 이름을 리스트로 가져옵니다.\n","    random.Random(1337).shuffle(files)\n","    num_val_samples = int(0.2 * len(files))\n","    val_files = files[-num_val_samples:]\n","    for fname in val_files:  # shutil 모듈의 move 함수를 사용하여 파일을 하나의 위치에서 다른 위치로 이동\n","        shutil.move(train_dir / category / fname,\n","                    val_dir / category / fname)"]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-dGGEdJ-Jck1","executionInfo":{"status":"ok","timestamp":1689166146488,"user_tz":-540,"elapsed":12,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"42980944-7f7f-4f0d-bb45-d3e5a5f5c167"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["aclImdb  aclImdb_v1.tar.gz  sample_data\n"]}]},{"cell_type":"code","execution_count":15,"metadata":{"id":"nCA9IoOKPHWI","outputId":"0e8fb8d7-bc4d-4fa2-8866-19ce987e41a2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689216219709,"user_tz":-540,"elapsed":2845,"user":{"displayName":"kevin park","userId":"02703084888761299921"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 20000 files belonging to 2 classes.\n","Found 5000 files belonging to 2 classes.\n","Found 25000 files belonging to 2 classes.\n"]}],"source":["from tensorflow import keras\n","batch_size = 32\n","\n","train_ds = keras.utils.text_dataset_from_directory( # 특정 디렉토리로부터 데이터셋을 생성\n","    \"aclImdb/train\", batch_size=batch_size\n",")\n","val_ds = keras.utils.text_dataset_from_directory(\n","    \"aclImdb/val\", batch_size=batch_size\n",")\n","test_ds = keras.utils.text_dataset_from_directory(\n","    \"aclImdb/test\", batch_size=batch_size\n",")"]},{"cell_type":"markdown","metadata":{"id":"F6IhmydcPHWI"},"source":["**첫 번째 배치의 크기와 dtype 출력하기**"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"RO58kApSPHWI","outputId":"bcbab840-1601-4402-f5af-6b389e28dbc7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689216427157,"user_tz":-540,"elapsed":340,"user":{"displayName":"kevin park","userId":"02703084888761299921"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["inputs.shape: (32,)\n","inputs.dtype: <dtype: 'string'>\n","targets.shape: (32,)\n","targets.dtype: <dtype: 'int32'>\n","inputs[0]: tf.Tensor(b'An interesting TV movie based on true fact, betrayed by the description of one of the leading characters, that of a prisoner. Giovanni Ribisi plays his younger brother, who has the delicate mission of deciding if he will appeal to the courts for his brother\\'s death penalty. But when he goes to visit him and enters Elias Koteas, the problem starts. It has nothing to do with Koteas\\' acting ability. He just looks like the version of a prisoner of proletarian roots according to \"G.Q.\" magazine, with a language too sophisticated for someone who has spent most of his life behind bars. This realization came to me after meeting again an old friend, whom I had not seen for almost 15 years, which he spent in several Panamanian jails. The young man I used to know is gone, not only because he is older, but due to his exposure for a prolonged time to the penal system. There are jails and there are jails, one must say, but this one prisoner in \"Shot In the Heart\" is definitely out of this world.', shape=(), dtype=string)\n","targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"]}],"source":["for inputs, targets in train_ds:\n","    print(\"inputs.shape:\", inputs.shape)\n","    print(\"inputs.dtype:\", inputs.dtype)\n","    print(\"targets.shape:\", targets.shape)\n","    print(\"targets.dtype:\", targets.dtype)\n","    print(\"inputs[0]:\", inputs[0])\n","    print(\"targets[0]:\", targets[0])\n","    break"]},{"cell_type":"markdown","metadata":{"id":"hRRDlnqAPHWJ"},"source":["### 단어를 집합으로 처리하기: BoW 방식"]},{"cell_type":"markdown","metadata":{"id":"uFc9dZA5PHWJ"},"source":["#### Single words (unigrams) with binary encoding"]},{"cell_type":"markdown","metadata":{"id":"r4_cyPXEPHWJ"},"source":["**`TextVectorization` 층으로 데이터 전처리하기**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eOSiAiGPPHWJ"},"outputs":[],"source":["# TextVectorization 레이어를 사용하여 텍스트 데이터를 전처리\n","from tensorflow.keras.layers import TextVectorization\n","\n","text_vectorization = TextVectorization(\n","    max_tokens=20000,\n","    output_mode=\"multi_hot\", # Multi-hot 인코딩은 텍스트에서 각 단어가 존재하는지 여부만 표시, 각 단어가 문서에 포함되면 1, 그렇지 않으면 0\n",")\n","text_only_train_ds = train_ds.map(lambda x, y: x) # 텍스트 데이터만 사용하여 어휘를 구축\n","text_vectorization.adapt(text_only_train_ds)\n","\n","binary_1gram_train_ds = train_ds.map(\n","    lambda x, y: (text_vectorization(x), y), # 입력 텍스트 x를 multi-hot 인코딩으로 변환하고 레이블 y를 그대로 둔다.\n","    num_parallel_calls=4) # num_parallel_calls=4는 동시에 4개의 병렬 작업을 사용하여 map 함수를 실행\n","binary_1gram_val_ds = val_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","binary_1gram_test_ds = test_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)"]},{"cell_type":"markdown","metadata":{"id":"XZp__LNzPHWJ"},"source":["**이진 유니그램 데이터셋의 출력 확인하기**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aKTPekqmPHWJ","outputId":"78e8bae7-bdf6-48be-f92c-3474d3155cc6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689168338611,"user_tz":-540,"elapsed":486,"user":{"displayName":"kevin park","userId":"02703084888761299921"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["inputs.shape: (32, 20000)\n","inputs.dtype: <dtype: 'float32'>\n","targets.shape: (32,)\n","targets.dtype: <dtype: 'int32'>\n","inputs[0]: tf.Tensor([1. 1. 1. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n","targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"]}],"source":["for inputs, targets in binary_1gram_train_ds:\n","    print(\"inputs.shape:\", inputs.shape)\n","    print(\"inputs.dtype:\", inputs.dtype)\n","    print(\"targets.shape:\", targets.shape)\n","    print(\"targets.dtype:\", targets.dtype)\n","    print(\"inputs[0]:\", inputs[0])\n","    print(\"targets[0]:\", targets[0])\n","    break"]},{"cell_type":"markdown","metadata":{"id":"-zCVeBuAPHWJ"},"source":["**모델 생성 유틸리티**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ODGXYjUcPHWK"},"outputs":[],"source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","def get_model(max_tokens=20000, hidden_dim=16):\n","    inputs = keras.Input(shape=(max_tokens,))\n","    x = layers.Dense(hidden_dim, activation=\"relu\")(inputs)\n","    x = layers.Dropout(0.5)(x)\n","    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","    model = keras.Model(inputs, outputs)\n","    model.compile(optimizer=\"rmsprop\",\n","                  loss=\"binary_crossentropy\",\n","                  metrics=[\"accuracy\"])\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"R2vbysS9PHWK"},"source":["**이진 유니그램 모델 훈련하고 테스트하기**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fmb0uHkyPHWK","outputId":"1cbe3cb5-5496-4358-f465-bfac3e6616a0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689168508948,"user_tz":-540,"elapsed":60947,"user":{"displayName":"kevin park","userId":"02703084888761299921"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 20000)]           0         \n","                                                                 \n"," dense (Dense)               (None, 16)                320016    \n","                                                                 \n"," dropout (Dropout)           (None, 16)                0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 17        \n","                                                                 \n","=================================================================\n","Total params: 320,033\n","Trainable params: 320,033\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","625/625 [==============================] - 11s 10ms/step - loss: 0.4110 - accuracy: 0.8238 - val_loss: 0.2985 - val_accuracy: 0.8822\n","Epoch 2/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2766 - accuracy: 0.8983 - val_loss: 0.2922 - val_accuracy: 0.8894\n","Epoch 3/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2467 - accuracy: 0.9132 - val_loss: 0.3018 - val_accuracy: 0.8870\n","Epoch 4/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2306 - accuracy: 0.9226 - val_loss: 0.3155 - val_accuracy: 0.8876\n","Epoch 5/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2244 - accuracy: 0.9266 - val_loss: 0.3296 - val_accuracy: 0.8902\n","Epoch 6/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2150 - accuracy: 0.9305 - val_loss: 0.3428 - val_accuracy: 0.8872\n","Epoch 7/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.2104 - accuracy: 0.9334 - val_loss: 0.3573 - val_accuracy: 0.8814\n","Epoch 8/10\n","625/625 [==============================] - 4s 6ms/step - loss: 0.1982 - accuracy: 0.9358 - val_loss: 0.3737 - val_accuracy: 0.8816\n","Epoch 9/10\n","625/625 [==============================] - 4s 6ms/step - loss: 0.1977 - accuracy: 0.9373 - val_loss: 0.3818 - val_accuracy: 0.8782\n","Epoch 10/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.2049 - accuracy: 0.9384 - val_loss: 0.3877 - val_accuracy: 0.8764\n","782/782 [==============================] - 4s 5ms/step - loss: 0.2890 - accuracy: 0.8870\n","테스트 정확도: 0.887\n"]}],"source":["model = get_model() # get_model()을 호출하여 딥 러닝 모델을 생성\n","model.summary()\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\"binary_1gram.keras\",\n","                                    save_best_only=True) # 모델의 검증 성능이 향상될 때만 가중치를 저장\n","]\n","model.fit(binary_1gram_train_ds.cache(), # .cache() 메서드는 데이터를 메모리에 캐시하여 데이터 로딩 속도를 높이는 역할\n","          validation_data=binary_1gram_val_ds.cache(),\n","          epochs=10,\n","          callbacks=callbacks)\n","model = keras.models.load_model(\"binary_1gram.keras\")\n","print(f\"테스트 정확도: {model.evaluate(binary_1gram_test_ds)[1]:.3f}\")"]},{"cell_type":"markdown","metadata":{"id":"tbLjMnm6PHWK"},"source":["#### 이진 인코딩을 사용한 바이그램"]},{"cell_type":"markdown","metadata":{"id":"HqKkpvj3PHWK"},"source":["**바이그램을 반환하는 `TextVectorization` 층 만들기**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O_xsjJvdPHWK"},"outputs":[],"source":["text_vectorization = TextVectorization(\n","    ngrams=2,\n","    max_tokens=20000,\n","    output_mode=\"multi_hot\",\n",")"]},{"cell_type":"markdown","metadata":{"id":"mdWi9dhXPHWL"},"source":["**이진 바이그램 모델 훈련하고 테스트하기**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7hJTKCooPHWL","outputId":"ddc1c363-7b82-4c82-8fdd-0ba9cd21cbf6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689168696900,"user_tz":-540,"elapsed":60637,"user":{"displayName":"kevin park","userId":"02703084888761299921"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 20000)]           0         \n","                                                                 \n"," dense_2 (Dense)             (None, 16)                320016    \n","                                                                 \n"," dropout_1 (Dropout)         (None, 16)                0         \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 17        \n","                                                                 \n","=================================================================\n","Total params: 320,033\n","Trainable params: 320,033\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","625/625 [==============================] - 8s 12ms/step - loss: 0.3782 - accuracy: 0.8446 - val_loss: 0.2781 - val_accuracy: 0.8908\n","Epoch 2/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2364 - accuracy: 0.9168 - val_loss: 0.2844 - val_accuracy: 0.8900\n","Epoch 3/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2078 - accuracy: 0.9322 - val_loss: 0.2998 - val_accuracy: 0.8890\n","Epoch 4/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.1907 - accuracy: 0.9410 - val_loss: 0.3139 - val_accuracy: 0.8896\n","Epoch 5/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.1772 - accuracy: 0.9481 - val_loss: 0.3347 - val_accuracy: 0.8890\n","Epoch 6/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.1645 - accuracy: 0.9505 - val_loss: 0.3518 - val_accuracy: 0.8874\n","Epoch 7/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.1619 - accuracy: 0.9538 - val_loss: 0.3683 - val_accuracy: 0.8830\n","Epoch 8/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.1584 - accuracy: 0.9541 - val_loss: 0.3783 - val_accuracy: 0.8844\n","Epoch 9/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.1547 - accuracy: 0.9570 - val_loss: 0.3886 - val_accuracy: 0.8824\n","Epoch 10/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.1503 - accuracy: 0.9577 - val_loss: 0.4035 - val_accuracy: 0.8834\n","782/782 [==============================] - 5s 6ms/step - loss: 0.2680 - accuracy: 0.8970\n","테스트 정확도: 0.897\n"]}],"source":["text_vectorization.adapt(text_only_train_ds)\n","binary_2gram_train_ds = train_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","binary_2gram_val_ds = val_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","binary_2gram_test_ds = test_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","\n","model = get_model()\n","model.summary()\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\"binary_2gram.keras\",\n","                                    save_best_only=True)\n","]\n","model.fit(binary_2gram_train_ds.cache(),\n","          validation_data=binary_2gram_val_ds.cache(),\n","          epochs=10,\n","          callbacks=callbacks)\n","model = keras.models.load_model(\"binary_2gram.keras\")\n","print(f\"테스트 정확도: {model.evaluate(binary_2gram_test_ds)[1]:.3f}\")"]},{"cell_type":"markdown","metadata":{"id":"vJTgC5qDPHWL"},"source":["#### TF-IDF 인코딩을 사용한 바이그램"]},{"cell_type":"markdown","metadata":{"id":"R6zaQL_wPHWL"},"source":["**토큰 카운트를 반환하는 `TextVectorization` 층**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TAHAvzsgPHWL"},"outputs":[],"source":["text_vectorization = TextVectorization(\n","    ngrams=2,\n","    max_tokens=20000,\n","    output_mode=\"count\"\n",")"]},{"cell_type":"markdown","metadata":{"id":"ukzyV24GPHWL"},"source":["**TF-IDF 가중치가 적용된 출력을 반환하는 `TextVectorization` 층**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Um9A6ydPHWL"},"outputs":[],"source":["text_vectorization = TextVectorization(\n","    ngrams=2,\n","    max_tokens=20000,\n","    output_mode=\"tf_idf\",\n",")"]},{"cell_type":"markdown","metadata":{"id":"BwoBv2nqPHWM"},"source":["**TF-IDF 바이그램 모델 훈련하고 테스트하기**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AGhSasurPHWM","outputId":"5c74f2ed-fd1c-4223-bba3-7db5bde94b8f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689168829995,"user_tz":-540,"elapsed":66179,"user":{"displayName":"kevin park","userId":"02703084888761299921"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_3 (InputLayer)        [(None, 20000)]           0         \n","                                                                 \n"," dense_4 (Dense)             (None, 16)                320016    \n","                                                                 \n"," dropout_2 (Dropout)         (None, 16)                0         \n","                                                                 \n"," dense_5 (Dense)             (None, 1)                 17        \n","                                                                 \n","=================================================================\n","Total params: 320,033\n","Trainable params: 320,033\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","625/625 [==============================] - 8s 10ms/step - loss: 0.5218 - accuracy: 0.7720 - val_loss: 0.3704 - val_accuracy: 0.8652\n","Epoch 2/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.3594 - accuracy: 0.8572 - val_loss: 0.3281 - val_accuracy: 0.8740\n","Epoch 3/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.3179 - accuracy: 0.8770 - val_loss: 0.3114 - val_accuracy: 0.8798\n","Epoch 4/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2941 - accuracy: 0.8875 - val_loss: 0.3279 - val_accuracy: 0.8752\n","Epoch 5/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2831 - accuracy: 0.8874 - val_loss: 0.3654 - val_accuracy: 0.8590\n","Epoch 6/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.2669 - accuracy: 0.8961 - val_loss: 0.3671 - val_accuracy: 0.8650\n","Epoch 7/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2595 - accuracy: 0.8992 - val_loss: 0.3732 - val_accuracy: 0.8652\n","Epoch 8/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.2511 - accuracy: 0.9025 - val_loss: 0.4062 - val_accuracy: 0.8600\n","Epoch 9/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.2448 - accuracy: 0.9081 - val_loss: 0.3956 - val_accuracy: 0.8628\n","Epoch 10/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.2441 - accuracy: 0.9107 - val_loss: 0.4213 - val_accuracy: 0.8488\n","782/782 [==============================] - 5s 6ms/step - loss: 0.2928 - accuracy: 0.8835\n","테스트 정확도: 0.884\n"]}],"source":["# 텐서플로 2.8.x 버전에서 TF-IDF 인코딩을 GPU에서 수행할 때 오류가 발생할 수 있습니다.\n","# 텐서플로 2.9에서 이 이슈가 해결되었지만 코드를 테스트할 시점에 코랩의 텐서플로 버전은 2.8.2이기 때문에\n","# 에러를 피하기 위해 CPU를 사용하여 텍스트를 변환합니다.\n","import tensorflow as tf\n","\n","with tf.device(\"cpu\"):\n","    text_vectorization.adapt(text_only_train_ds)\n","\n","tfidf_2gram_train_ds = train_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","tfidf_2gram_val_ds = val_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","tfidf_2gram_test_ds = test_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","\n","model = get_model()\n","model.summary()\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\"tfidf_2gram.keras\",\n","                                    save_best_only=True)\n","]\n","model.fit(tfidf_2gram_train_ds.cache(),\n","          validation_data=tfidf_2gram_val_ds.cache(),\n","          epochs=10,\n","          callbacks=callbacks)\n","model = keras.models.load_model(\"tfidf_2gram.keras\")\n","print(f\"테스트 정확도: {model.evaluate(tfidf_2gram_test_ds)[1]:.3f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tGIbe1KrPHWM"},"outputs":[],"source":["inputs = keras.Input(shape=(1,), dtype=\"string\")\n","processed_inputs = text_vectorization(inputs)\n","outputs = model(processed_inputs)\n","inference_model = keras.Model(inputs, outputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XBEraM_0PHWM","outputId":"f311a28e-bf85-4201-bd2c-4c4fbf85d85d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689168858807,"user_tz":-540,"elapsed":474,"user":{"displayName":"kevin park","userId":"02703084888761299921"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["긍정적인 리뷰일 확률: 91.12 퍼센트\n"]}],"source":["import tensorflow as tf\n","raw_text_data = tf.convert_to_tensor([\n","    [\"That was an excellent movie, I loved it.\"],\n","])\n","predictions = inference_model(raw_text_data)\n","print(f\"긍정적인 리뷰일 확률: {float(predictions[0] * 100):.2f} 퍼센트\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"default:Python","language":"python","name":"conda-env-default-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}